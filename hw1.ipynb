{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECE HW 1\n",
    "# NetID = \"somani4\"\n",
    "# Name = \"Akhilesh Somani\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part A: Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in pf.log\n",
    "with open(\"pf.log\",'r') as f:\n",
    "    lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = [x.strip() for x in lines]\n",
    "# strip all lines of whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse each line into your data structure\n",
    "my_dict={}\n",
    "z_backtrace=[]\n",
    "\n",
    "for line in lines:\n",
    "    \n",
    "    x=line.split(\":\")\n",
    "    if len(x)==7:\n",
    "        z_info=(x[0],x[1],x[2],int(x[3],16),x[4],x[5],x[6])\n",
    "        z_backtrace=[]\n",
    "    else:\n",
    "        second_half=line.split(\"+\")\n",
    "        temp=second_half[1].split(\"/\")\n",
    "        z_backtrace_temp=[second_half[0].lstrip('<'),int(temp[1].rstrip('>'),16), int(temp[0],16)]\n",
    "        z_backtrace.append(z_backtrace_temp)\n",
    "    \n",
    "    \n",
    "    my_dict[z_info]=z_backtrace    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'pf.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-3f8e3c4e243c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# include an index column with unique indices for each page fault\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'pf.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;31m# write header line\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\t'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'index'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'time'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'proc_name'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'pid'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'pfaddr'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rw'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'major_minor'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'resolve_time'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'lib'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'addr'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'offset'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'pf.csv'"
     ]
    }
   ],
   "source": [
    "# write your data structure out to pf.csv\n",
    "# include an index column with unique indices for each page fault\n",
    "\n",
    "with open('pf.csv', 'w') as f:\n",
    "    # write header line\n",
    "    f.write('\\t'.join(['index', 'time', 'proc_name', 'pid', 'pfaddr', 'rw', 'major_minor', 'resolve_time', 'lib', 'addr', 'offset']))\n",
    "    f.write('\\n')\n",
    "    \n",
    "    data_entry=[]\n",
    "    for i, key in enumerate (my_dict.keys()):\n",
    "        for value in my_dict[key]:\n",
    "            data_entry.append([i+1]+list(key)+value)\n",
    "            \n",
    "    for entry in data_entry:\n",
    "        entry[0]=str(entry[0])\n",
    "        entry[4]=str(entry[4])\n",
    "        entry[-1]=str(entry[-1])\n",
    "        entry[-2]=str(entry[-2])\n",
    "    \n",
    "    \n",
    "    for entry in data_entry:\n",
    "        f.write('\\t'.join(entry))\n",
    "        f.write('\\n')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part B: Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mlab\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# relevant options when reading in pf.csv: sep, parse_dates\n",
    "df = pd.read_csv('pf_trial1.csv', sep = '\\t', parse_dates = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df['time']=pd.to_datetime(df['time'],unit='ms')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question [B] (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"The time that the data ranges is from {0} to {1}\".format(df['time'].min(),df['time'].max()) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question [B] (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of unique processes run are: {0}\".format(len(df.groupby('proc_name'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "my_df = df.set_index('index')\n",
    "my_df = my_df.loc[~my_df.index.duplicated(keep='first')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(my_df['proc_name'].value_counts(sort=False, ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question [B] (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df['major_minor'].value_counts(sort=False, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_values1=my_df['major_minor'].value_counts()['major']\n",
    "\n",
    "y_values2=my_df['major_minor'].value_counts()['minor']\n",
    "    \n",
    "column_names=my_df.columns\n",
    "column_names=list(column_names)\n",
    "column_names.remove('major_minor')\n",
    "\n",
    "x_label=np.arange(len(column_names))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "\n",
    "bar1=plt.bar(x_label, y_values1, width = 0.4, bottom = None, align='edge',color='b',label='Major Fault')\n",
    "bar2=plt.bar(x_label, y_values2, width = -0.4, bottom = None, align='edge',color='r',label='Minor Fault')\n",
    "\n",
    "\n",
    "plt.xlabel('Other information parameters about the page fault',fontsize=25)\n",
    "plt.ylabel('Number of Page Faults', fontsize=25)\n",
    "plt.xticks(x_label,column_names)\n",
    "plt.legend()\n",
    "ax.tick_params(axis='both', which='major', labelsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question [B] (d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "time_major = [my_df.at[row+1,'resolve_time'] for row in range(len(my_df)) if my_df.at[row+1,'major_minor'] == 'major']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax =plt.subplots(figsize=(20,10))\n",
    "plt.hist(time_major, bins=200) \n",
    "plt.xlabel('Resolve Time (ms)',fontsize=25)\n",
    "plt.ylabel('Number', fontsize=25)\n",
    "plt.title('Resolve Time for Major Faults',fontsize=25)\n",
    "ax.tick_params(axis='both', which='major', labelsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_minor = [my_df.at[row+1,'resolve_time'] for row in range(len(my_df)) if my_df.at[row+1,'major_minor'] == 'minor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig,ax =plt.subplots(figsize=(20,10))\n",
    "plt.hist(time_minor, bins=50) \n",
    "plt.xlabel('Resolve Time (ms)',fontsize=25)\n",
    "plt.ylabel('Number', fontsize=25)\n",
    "plt.title('Resolve Time for Minor Faults',fontsize=25)\n",
    "ax.tick_params(axis='both', which='major', labelsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_names= my_df['proc_name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_table_major=my_df.loc[(my_df['major_minor']=='major')].groupby(my_df.proc_name,sort=False).mean()\n",
    "std_table_major=my_df.loc[(my_df['major_minor']=='major')].groupby(my_df.proc_name,sort=False).std()\n",
    "\n",
    "mean_table_minor=my_df.loc[(my_df['major_minor']=='minor')].groupby(my_df.proc_name,sort=False).mean()\n",
    "std_table_minor=my_df.loc[(my_df['major_minor']=='minor')].groupby(my_df.proc_name,sort=False).std()\n",
    "\n",
    "process_names= my_df['proc_name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for process in process_names:\n",
    "    print(\"***********For Process: {0}, the results are: \\n\".format(process))\n",
    "    print(\"Major Faults: \\n (1) Mean: {0} ms \\n (2) Standard Deviation: {1} ms \\n \\n\".format(mean_table_major.loc[process,'resolve_time'], std_table_major.loc[process,'resolve_time']))\n",
    "    print(\"Minor Faults: \\n (1) Mean: {0} ms \\n (2) Standard Deviation: {1} ms \\n \\n\".format(mean_table_minor.loc[process,'resolve_time'], std_table_minor.loc[process,'resolve_time']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part C: Making Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question [C] (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Priors=my_df['proc_name'].value_counts(sort=False)/my_df['proc_name'].value_counts(sort=False, ascending=False).sum()\n",
    "Priors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question [C] (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ P (C = process | Type = Major Fault) ∝ P (Type = Major Fault | C = process)*P(C=process) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "z=my_df.groupby(['proc_name','major_minor']).count()\n",
    "p_major=[]\n",
    "#p_minor=[]\n",
    "\n",
    "for process in process_names:\n",
    "    p_major.append((z.loc[(process,'major'),'time']/my_df['proc_name'].value_counts()[process])*Priors[process])\n",
    "    #p_minor.append((z.loc[(process,'minor'),'time']/my_df['proc_name'].value_counts()[process])*Priors[process])\n",
    "\n",
    "#MAP RULE\n",
    "max_major=max(p_major)\n",
    "#max_min=max(p_minor)\n",
    "\n",
    "i_major = [i for i in range(len(p_major)) if p_major[i]==max_major]\n",
    "\n",
    "#[i_minor for i_minor in range(len(p_minor)) if p_minor[i]==max_minor]\n",
    "\n",
    "print(\"Given the fault was major, it was most likely caused by process: {0}\".format(process_names[i_major[0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question [C] (c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ P (C = process | Access = Read) ∝ P (Access = Read | C = process)*P(C=process) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z=my_df.groupby(['proc_name','rw']).count()\n",
    "p_r=[]\n",
    "\n",
    "for process in process_names:\n",
    "    p_r.append((z.loc[(process,'R'),'time']/my_df['proc_name'].value_counts()[process])*Priors[process])\n",
    "    \n",
    "#MAP RULE\n",
    "max_r=max(p_r)\n",
    "\n",
    "i_r = [i for i in range(len(p_r)) if p_r[i]==max_r]\n",
    "\n",
    "print(\"Given the fault was due to read access, it was most likely caused by process: {0}\".format(process_names[i_r[0]]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
